2024-10-18 11:37:36,439:INFO:Starting the pipeline with the following steps: ['data_validation', 'configure_prompt_version', 'test_model', 'analyze_results', 'manage_experiment_logs', 'generate_visualizations']
2024-10-18 11:37:36,439:INFO:Starting data validation...
2024-10-18 11:37:37,650:INFO:Simple examples loaded successfully.
2024-10-18 11:37:37,651:INFO:Complex examples loaded successfully.
2024-10-18 11:37:37,695:INFO:Data validation completed successfully. All entries conform to the schema.
2024-10-18 11:37:37,695:INFO:Updating prompt versions...
2024-10-18 11:37:37,965:INFO:Deploying models...
2024-10-18 11:37:39,080:INFO:Parameters for model Qwen 2.5-coder (7B) quantized 4bit configured successfully.
2024-10-18 11:37:39,081:ERROR:An error occurred: 'dict' object is not callable
2024-10-18 11:40:54,497:INFO:Starting the pipeline with the following steps: ['data_validation', 'configure_prompt_version', 'test_model', 'analyze_results', 'manage_experiment_logs', 'generate_visualizations']
2024-10-18 11:40:54,498:INFO:Starting data validation...
2024-10-18 11:40:55,434:INFO:Simple examples loaded successfully.
2024-10-18 11:40:55,435:INFO:Complex examples loaded successfully.
2024-10-18 11:40:55,481:INFO:Data validation completed successfully. All entries conform to the schema.
2024-10-18 11:40:55,481:INFO:Updating prompt versions...
2024-10-18 11:40:56,142:INFO:Deploying models...
2024-10-18 11:40:58,885:INFO:Parameters for model Qwen 2.5-coder (7B) quantized 4bit configured successfully.
2024-10-18 11:40:58,885:ERROR:Unexpected error in __main__.deploy_selected_model: 'dict' object is not callable
2024-10-18 11:40:58,885:INFO:Process completed successfully.
2024-10-18 11:43:12,108:INFO:Starting the pipeline with the following steps: ['data_validation', 'configure_prompt_version', 'test_model', 'analyze_results', 'manage_experiment_logs', 'generate_visualizations']
2024-10-18 11:43:12,108:INFO:Starting data validation...
2024-10-18 11:43:13,420:INFO:Simple examples loaded successfully.
2024-10-18 11:43:13,420:INFO:Complex examples loaded successfully.
2024-10-18 11:43:13,452:INFO:Data validation completed successfully. All entries conform to the schema.
2024-10-18 11:43:13,452:INFO:Updating prompt versions...
2024-10-18 11:43:13,867:INFO:Deploying models...
2024-10-18 11:43:13,869:INFO:Available supported models: ['Qwen 2.5-coder (7B) quantized 4bit', 'Qwen 2.5-coder (7B) full precision', 'Qwen 2.5 (32B) full precision', 'Qwen 2.5 (72B) quantized 4bit', 'Qwen 2.5 (72B) quantized 8bit', 'Codellama (7B) full precision', 'Codellama (13B) full precision', 'Codellama (34B) full precision', 'Codellama (70B) full precision', 'LLaMA 3.1 (8B) full precision', 'LLaMA 3.1 (70B) quantized 4bit', 'LLaMA 3.1 (70B) quantized 8bit', 'StarCoder2 (3B) full precision', 'StarCoder2 (7B) full precision', 'StarCoder2 (15B) full precision', 'Mistral (7B) full precision', 'OpenAI GPT4o']
2024-10-18 11:43:14,699:INFO:Selected model: Qwen 2.5-coder (7B) quantized 4bit
2024-10-18 11:43:16,817:INFO:Parameters for model Qwen 2.5-coder (7B) quantized 4bit configured successfully.
2024-10-18 11:43:16,817:ERROR:Unexpected error in __main__.deploy_selected_model: 'dict' object is not callable
2024-10-18 11:43:16,818:INFO:Process completed successfully.
2024-10-18 11:46:25,417:INFO:Starting the pipeline with the following steps: ['data_validation', 'configure_prompt_version', 'test_model', 'analyze_results', 'manage_experiment_logs', 'generate_visualizations']
2024-10-18 11:46:25,418:INFO:Starting data validation...
2024-10-18 11:46:26,951:INFO:Simple examples loaded successfully.
2024-10-18 11:46:26,953:INFO:Complex examples loaded successfully.
2024-10-18 11:46:26,998:INFO:Data validation completed successfully. All entries conform to the schema.
2024-10-18 11:46:26,998:INFO:Updating prompt versions...
2024-10-18 11:46:27,744:INFO:Deploying models...
2024-10-18 11:46:27,747:INFO:Available supported models: ['Qwen 2.5-coder (7B) quantized 4bit', 'Qwen 2.5-coder (7B) full precision', 'Qwen 2.5 (32B) full precision', 'Qwen 2.5 (72B) quantized 4bit', 'Qwen 2.5 (72B) quantized 8bit', 'Codellama (7B) full precision', 'Codellama (13B) full precision', 'Codellama (34B) full precision', 'Codellama (70B) full precision', 'LLaMA 3.1 (8B) full precision', 'LLaMA 3.1 (70B) quantized 4bit', 'LLaMA 3.1 (70B) quantized 8bit', 'StarCoder2 (3B) full precision', 'StarCoder2 (7B) full precision', 'StarCoder2 (15B) full precision', 'Mistral (7B) full precision', 'OpenAI GPT4o']
2024-10-18 11:46:29,244:INFO:Selected model: Qwen 2.5-coder (7B) quantized 4bit
2024-10-18 11:46:29,553:INFO:Parameters for model Qwen 2.5-coder (7B) quantized 4bit configured successfully.
2024-10-18 11:46:29,553:ERROR:Error loading data for testing: 'dict' object is not callable
2024-10-18 11:46:29,554:ERROR:Traceback: Traceback (most recent call last):
  File "/Users/lucasala/Documents/Projects/Maktaba/text-to-DSL/scripts/model_testing.py", line 61, in test_model
    real_data = config(config['paths']['data_directory'] + 'simple_examples.json',
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: 'dict' object is not callable

2024-10-18 11:46:29,554:ERROR:Model {'model_name': 'Qwen 2.5-coder quantized 4bit', 'type': 'open source', 'supported': True, 'ollama_command': 'ollama run qwen2.5-coder:7b-instruct-q4_1', 'vram_requirement': '5GB', 'deployment_type': 'local', 'temperature': 1, 'num_ctx': 128000, 'num_predict': 2024} failed testing.
2024-10-18 11:46:29,554:INFO:Process completed successfully.
2024-10-18 11:49:09,131:INFO:Starting the pipeline with the following steps: ['data_validation', 'configure_prompt_version', 'test_model', 'analyze_results', 'manage_experiment_logs', 'generate_visualizations']
2024-10-18 11:49:09,132:INFO:Starting data validation...
2024-10-18 11:49:10,731:INFO:Simple examples loaded successfully.
2024-10-18 11:49:10,732:INFO:Complex examples loaded successfully.
2024-10-18 11:49:10,765:INFO:Data validation completed successfully. All entries conform to the schema.
2024-10-18 11:49:10,765:INFO:Updating prompt versions...
2024-10-18 11:49:11,224:INFO:Deploying models...
2024-10-18 11:49:11,226:INFO:Available supported models: ['Qwen 2.5-coder (7B) quantized 4bit', 'Qwen 2.5-coder (7B) full precision', 'Qwen 2.5 (32B) full precision', 'Qwen 2.5 (72B) quantized 4bit', 'Qwen 2.5 (72B) quantized 8bit', 'Codellama (7B) full precision', 'Codellama (13B) full precision', 'Codellama (34B) full precision', 'Codellama (70B) full precision', 'LLaMA 3.1 (8B) full precision', 'LLaMA 3.1 (70B) quantized 4bit', 'LLaMA 3.1 (70B) quantized 8bit', 'StarCoder2 (3B) full precision', 'StarCoder2 (7B) full precision', 'StarCoder2 (15B) full precision', 'Mistral (7B) full precision', 'OpenAI GPT4o']
2024-10-18 11:49:11,930:INFO:Selected model: Qwen 2.5-coder (7B) quantized 4bit
2024-10-18 11:49:12,422:INFO:Parameters for model Qwen 2.5-coder (7B) quantized 4bit configured successfully.
2024-10-18 11:49:12,422:ERROR:File not found: [Errno 2] No such file or directory: 'data/simple_examples.json'
2024-10-18 11:49:12,423:ERROR:Traceback: Traceback (most recent call last):
  File "/Users/lucasala/Documents/Projects/Maktaba/text-to-DSL/scripts/model_testing.py", line 64, in test_model
    json.load(open(config['paths']['data_directory'] + file, 'r'))
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'data/simple_examples.json'

2024-10-18 11:49:12,423:ERROR:Model {'model_name': 'Qwen 2.5-coder quantized 4bit', 'type': 'open source', 'supported': True, 'ollama_command': 'ollama run qwen2.5-coder:7b-instruct-q4_1', 'vram_requirement': '5GB', 'deployment_type': 'local', 'temperature': 1, 'num_ctx': 128000, 'num_predict': 2024} failed testing.
2024-10-18 11:49:12,424:INFO:Process completed successfully.
2024-10-18 11:50:53,390:INFO:Starting the pipeline with the following steps: ['data_validation', 'configure_prompt_version', 'test_model', 'analyze_results', 'manage_experiment_logs', 'generate_visualizations']
2024-10-18 11:50:53,391:INFO:Starting data validation...
2024-10-18 11:50:53,919:INFO:Simple examples loaded successfully.
2024-10-18 11:50:53,920:INFO:Complex examples loaded successfully.
2024-10-18 11:50:53,966:INFO:Data validation completed successfully. All entries conform to the schema.
2024-10-18 11:50:53,966:INFO:Updating prompt versions...
2024-10-18 11:50:54,155:INFO:Deploying models...
2024-10-18 11:50:54,156:INFO:Available supported models: ['Qwen 2.5-coder (7B) quantized 4bit', 'Qwen 2.5-coder (7B) full precision', 'Qwen 2.5 (32B) full precision', 'Qwen 2.5 (72B) quantized 4bit', 'Qwen 2.5 (72B) quantized 8bit', 'Codellama (7B) full precision', 'Codellama (13B) full precision', 'Codellama (34B) full precision', 'Codellama (70B) full precision', 'LLaMA 3.1 (8B) full precision', 'LLaMA 3.1 (70B) quantized 4bit', 'LLaMA 3.1 (70B) quantized 8bit', 'StarCoder2 (3B) full precision', 'StarCoder2 (7B) full precision', 'StarCoder2 (15B) full precision', 'Mistral (7B) full precision', 'OpenAI GPT4o']
2024-10-18 11:50:54,404:INFO:Selected model: Qwen 2.5-coder (7B) quantized 4bit
2024-10-18 11:50:54,852:INFO:Parameters for model Qwen 2.5-coder (7B) quantized 4bit configured successfully.
2024-10-18 11:50:54,853:ERROR:File not found: [Errno 2] No such file or directory: 'data/sensorssimple_examples.json'
2024-10-18 11:50:54,854:ERROR:Traceback: Traceback (most recent call last):
  File "/Users/lucasala/Documents/Projects/Maktaba/text-to-DSL/scripts/model_testing.py", line 64, in test_model
    json.load(open(config['paths']['data_directory']+ dataset_name + file, 'r'))
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'data/sensorssimple_examples.json'

2024-10-18 11:50:54,854:ERROR:Model {'model_name': 'Qwen 2.5-coder quantized 4bit', 'type': 'open source', 'supported': True, 'ollama_command': 'ollama run qwen2.5-coder:7b-instruct-q4_1', 'vram_requirement': '5GB', 'deployment_type': 'local', 'temperature': 1, 'num_ctx': 128000, 'num_predict': 2024} failed testing.
2024-10-18 11:50:54,854:INFO:Process completed successfully.
2024-10-18 11:51:19,084:INFO:Starting the pipeline with the following steps: ['data_validation', 'configure_prompt_version', 'test_model', 'analyze_results', 'manage_experiment_logs', 'generate_visualizations']
2024-10-18 11:51:19,084:INFO:Starting data validation...
2024-10-18 11:51:20,022:INFO:Simple examples loaded successfully.
2024-10-18 11:51:20,024:INFO:Complex examples loaded successfully.
2024-10-18 11:51:20,069:INFO:Data validation completed successfully. All entries conform to the schema.
2024-10-18 11:51:20,070:INFO:Updating prompt versions...
2024-10-18 11:51:20,293:INFO:Deploying models...
2024-10-18 11:51:20,295:INFO:Available supported models: ['Qwen 2.5-coder (7B) quantized 4bit', 'Qwen 2.5-coder (7B) full precision', 'Qwen 2.5 (32B) full precision', 'Qwen 2.5 (72B) quantized 4bit', 'Qwen 2.5 (72B) quantized 8bit', 'Codellama (7B) full precision', 'Codellama (13B) full precision', 'Codellama (34B) full precision', 'Codellama (70B) full precision', 'LLaMA 3.1 (8B) full precision', 'LLaMA 3.1 (70B) quantized 4bit', 'LLaMA 3.1 (70B) quantized 8bit', 'StarCoder2 (3B) full precision', 'StarCoder2 (7B) full precision', 'StarCoder2 (15B) full precision', 'Mistral (7B) full precision', 'OpenAI GPT4o']
2024-10-18 11:51:20,567:INFO:Selected model: Qwen 2.5-coder (7B) quantized 4bit
2024-10-18 11:51:21,134:INFO:Parameters for model Qwen 2.5-coder (7B) quantized 4bit configured successfully.
2024-10-18 11:51:21,135:ERROR:File not found: [Errno 2] No such file or directory: 'data/augmented_examples.json'
2024-10-18 11:51:21,136:ERROR:Traceback: Traceback (most recent call last):
  File "/Users/lucasala/Documents/Projects/Maktaba/text-to-DSL/scripts/model_testing.py", line 79, in test_model
    with open(config['paths']['data_directory'] + 'augmented_examples.json', 'r') as augmented_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'data/augmented_examples.json'

2024-10-18 11:51:21,136:ERROR:Model {'model_name': 'Qwen 2.5-coder quantized 4bit', 'type': 'open source', 'supported': True, 'ollama_command': 'ollama run qwen2.5-coder:7b-instruct-q4_1', 'vram_requirement': '5GB', 'deployment_type': 'local', 'temperature': 1, 'num_ctx': 128000, 'num_predict': 2024} failed testing.
2024-10-18 11:51:21,136:INFO:Process completed successfully.
2024-10-18 11:51:35,587:INFO:Starting the pipeline with the following steps: ['data_validation', 'configure_prompt_version', 'test_model', 'analyze_results', 'manage_experiment_logs', 'generate_visualizations']
2024-10-18 11:51:35,587:INFO:Starting data validation...
2024-10-18 11:51:36,052:INFO:Simple examples loaded successfully.
2024-10-18 11:51:36,052:INFO:Complex examples loaded successfully.
2024-10-18 11:51:36,090:INFO:Data validation completed successfully. All entries conform to the schema.
2024-10-18 11:51:36,090:INFO:Updating prompt versions...
2024-10-18 11:51:36,293:INFO:Deploying models...
2024-10-18 11:51:36,295:INFO:Available supported models: ['Qwen 2.5-coder (7B) quantized 4bit', 'Qwen 2.5-coder (7B) full precision', 'Qwen 2.5 (32B) full precision', 'Qwen 2.5 (72B) quantized 4bit', 'Qwen 2.5 (72B) quantized 8bit', 'Codellama (7B) full precision', 'Codellama (13B) full precision', 'Codellama (34B) full precision', 'Codellama (70B) full precision', 'LLaMA 3.1 (8B) full precision', 'LLaMA 3.1 (70B) quantized 4bit', 'LLaMA 3.1 (70B) quantized 8bit', 'StarCoder2 (3B) full precision', 'StarCoder2 (7B) full precision', 'StarCoder2 (15B) full precision', 'Mistral (7B) full precision', 'OpenAI GPT4o']
2024-10-18 11:51:36,518:INFO:Selected model: Qwen 2.5-coder (7B) quantized 4bit
2024-10-18 11:51:36,728:INFO:Parameters for model Qwen 2.5-coder (7B) quantized 4bit configured successfully.
2024-10-18 11:51:36,729:ERROR:File not found: [Errno 2] No such file or directory: 'data/sensors/augmented_examples.json'
2024-10-18 11:51:36,730:ERROR:Traceback: Traceback (most recent call last):
  File "/Users/lucasala/Documents/Projects/Maktaba/text-to-DSL/scripts/model_testing.py", line 79, in test_model
    with open(config['paths']['data_directory'] + dataset_name + '/' + 'augmented_examples.json', 'r') as augmented_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'data/sensors/augmented_examples.json'

2024-10-18 11:51:36,730:ERROR:Model {'model_name': 'Qwen 2.5-coder quantized 4bit', 'type': 'open source', 'supported': True, 'ollama_command': 'ollama run qwen2.5-coder:7b-instruct-q4_1', 'vram_requirement': '5GB', 'deployment_type': 'local', 'temperature': 1, 'num_ctx': 128000, 'num_predict': 2024} failed testing.
2024-10-18 11:51:36,730:INFO:Process completed successfully.
2024-10-18 11:52:52,550:INFO:Starting the pipeline with the following steps: ['data_validation', 'configure_prompt_version', 'test_model', 'analyze_results', 'manage_experiment_logs', 'generate_visualizations']
2024-10-18 11:52:52,551:INFO:Starting data validation...
2024-10-18 11:52:53,224:INFO:Simple examples loaded successfully.
2024-10-18 11:52:53,224:INFO:Complex examples loaded successfully.
2024-10-18 11:52:53,301:INFO:Data validation completed successfully. All entries conform to the schema.
2024-10-18 11:52:53,301:INFO:Updating prompt versions...
2024-10-18 11:52:53,535:INFO:Deploying models...
2024-10-18 11:52:53,536:INFO:Available supported models: ['Qwen 2.5-coder (7B) quantized 4bit', 'Qwen 2.5-coder (7B) full precision', 'Qwen 2.5 (32B) full precision', 'Qwen 2.5 (72B) quantized 4bit', 'Qwen 2.5 (72B) quantized 8bit', 'Codellama (7B) full precision', 'Codellama (13B) full precision', 'Codellama (34B) full precision', 'Codellama (70B) full precision', 'LLaMA 3.1 (8B) full precision', 'LLaMA 3.1 (70B) quantized 4bit', 'LLaMA 3.1 (70B) quantized 8bit', 'StarCoder2 (3B) full precision', 'StarCoder2 (7B) full precision', 'StarCoder2 (15B) full precision', 'Mistral (7B) full precision', 'OpenAI GPT4o']
2024-10-18 11:52:54,178:INFO:Selected model: Qwen 2.5-coder (7B) quantized 4bit
2024-10-18 11:52:54,822:INFO:Parameters for model Qwen 2.5-coder (7B) quantized 4bit configured successfully.
2024-10-18 11:52:54,823:WARNING:Synthetic data file not found: [Errno 2] No such file or directory: 'data/sensors/augmented_examples.json'. Continuing without synthetic data.
2024-10-18 11:52:54,823:ERROR:Unexpected error in __main__.deploy_selected_model: unhashable type: 'dict'
2024-10-18 11:52:54,823:INFO:Process completed successfully.
2024-10-18 11:55:20,307:INFO:Starting the pipeline with the following steps: ['data_validation', 'configure_prompt_version', 'test_model', 'analyze_results', 'manage_experiment_logs', 'generate_visualizations']
2024-10-18 11:55:20,307:INFO:Starting data validation...
2024-10-18 11:55:21,090:INFO:Simple examples loaded successfully.
2024-10-18 11:55:21,091:INFO:Complex examples loaded successfully.
2024-10-18 11:55:21,127:INFO:Data validation completed successfully. All entries conform to the schema.
2024-10-18 11:55:21,127:INFO:Updating prompt versions...
2024-10-18 11:55:21,306:INFO:Deploying models...
2024-10-18 11:55:21,309:INFO:Available supported models: ['Qwen 2.5-coder (7B) quantized 4bit', 'Qwen 2.5-coder (7B) full precision', 'Qwen 2.5 (32B) full precision', 'Qwen 2.5 (72B) quantized 4bit', 'Qwen 2.5 (72B) quantized 8bit', 'Codellama (7B) full precision', 'Codellama (13B) full precision', 'Codellama (34B) full precision', 'Codellama (70B) full precision', 'LLaMA 3.1 (8B) full precision', 'LLaMA 3.1 (70B) quantized 4bit', 'LLaMA 3.1 (70B) quantized 8bit', 'StarCoder2 (3B) full precision', 'StarCoder2 (7B) full precision', 'StarCoder2 (15B) full precision', 'Mistral (7B) full precision', 'OpenAI GPT4o']
2024-10-18 11:55:21,530:INFO:Selected model: Qwen 2.5-coder (7B) quantized 4bit
2024-10-18 11:55:22,003:INFO:Parameters for model Qwen 2.5-coder (7B) quantized 4bit configured successfully.
2024-10-18 11:55:22,004:WARNING:Synthetic data file not found: [Errno 2] No such file or directory: 'data/sensors/augmented_examples.json'. Continuing without synthetic data.
2024-10-18 11:55:22,004:ERROR:Unexpected error in __main__.deploy_selected_model: unhashable type: 'dict'
2024-10-18 11:55:22,006:ERROR:Traceback: Traceback (most recent call last):
  File "/Users/lucasala/Documents/Projects/Maktaba/text-to-DSL/main.py", line 40, in deploy_selected_model
    if test_model(dataset_name, selected_model, system_prompt_version):
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/lucasala/Documents/Projects/Maktaba/text-to-DSL/scripts/model_testing.py", line 96, in test_model
    model_config = load_model_config(model_name)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/lucasala/Documents/Projects/Maktaba/text-to-DSL/scripts/model_testing.py", line 30, in load_model_config
    model_config = all_model_configs.get(model_name, {})
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: unhashable type: 'dict'

2024-10-18 11:55:22,006:INFO:Process completed successfully.
2024-10-18 11:57:10,303:INFO:Starting the pipeline with the following steps: ['data_validation', 'configure_prompt_version', 'test_model', 'analyze_results', 'manage_experiment_logs', 'generate_visualizations']
2024-10-18 11:57:10,303:INFO:Starting data validation...
2024-10-18 11:57:10,932:INFO:Simple examples loaded successfully.
2024-10-18 11:57:10,933:INFO:Complex examples loaded successfully.
2024-10-18 11:57:10,973:INFO:Data validation completed successfully. All entries conform to the schema.
2024-10-18 11:57:10,973:INFO:Updating prompt versions...
2024-10-18 11:57:11,224:INFO:Deploying models...
2024-10-18 11:57:11,226:INFO:Available supported models: ['Qwen 2.5-coder (7B) quantized 4bit', 'Qwen 2.5-coder (7B) full precision', 'Qwen 2.5 (32B) full precision', 'Qwen 2.5 (72B) quantized 4bit', 'Qwen 2.5 (72B) quantized 8bit', 'Codellama (7B) full precision', 'Codellama (13B) full precision', 'Codellama (34B) full precision', 'Codellama (70B) full precision', 'LLaMA 3.1 (8B) full precision', 'LLaMA 3.1 (70B) quantized 4bit', 'LLaMA 3.1 (70B) quantized 8bit', 'StarCoder2 (3B) full precision', 'StarCoder2 (7B) full precision', 'StarCoder2 (15B) full precision', 'Mistral (7B) full precision', 'OpenAI GPT4o']
2024-10-18 11:57:11,473:INFO:Selected model: Qwen 2.5-coder (7B) quantized 4bit
2024-10-18 11:57:11,769:INFO:Parameters for model Qwen 2.5-coder (7B) quantized 4bit configured successfully.
2024-10-18 11:57:11,769:WARNING:Synthetic data file not found: [Errno 2] No such file or directory: 'data/sensors/augmented_examples.json'. Continuing without synthetic data.
2024-10-18 11:57:11,770:WARNING:No specific configuration found for model Qwen 2.5-coder quantized 4bit. Using default settings.
2024-10-18 11:57:11,770:ERROR:Unexpected error in __main__.deploy_selected_model: name 'model_parameters' is not defined
2024-10-18 11:57:11,776:ERROR:Traceback: Traceback (most recent call last):
  File "/Users/lucasala/Documents/Projects/Maktaba/text-to-DSL/main.py", line 41, in deploy_selected_model
    if test_model(dataset_name, selected_model_name, system_prompt_version):
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/lucasala/Documents/Projects/Maktaba/text-to-DSL/scripts/model_testing.py", line 98, in test_model
    logging.info(f"Testing model {model_name} with {len(data_to_test)} examples and parameters: {model_parameters}.")
                                                                                                 ^^^^^^^^^^^^^^^^
NameError: name 'model_parameters' is not defined

2024-10-18 11:57:11,776:INFO:Process completed successfully.
2024-10-18 12:27:44,575:INFO:Starting the pipeline with the following steps: ['data_validation', 'configure_prompt_version', 'test_model', 'analyze_results', 'manage_experiment_logs', 'generate_visualizations']
2024-10-18 12:27:44,575:INFO:Starting data validation...
2024-10-18 12:27:45,412:INFO:Simple examples loaded successfully.
2024-10-18 12:27:45,413:INFO:Complex examples loaded successfully.
2024-10-18 12:27:45,460:INFO:Data validation completed successfully. All entries conform to the schema.
2024-10-18 12:27:45,460:INFO:Updating prompt versions...
2024-10-18 12:27:45,933:INFO:Deploying models...
2024-10-18 12:27:45,935:INFO:Available supported models: ['Qwen 2.5-coder (7B) quantized 4bit', 'Qwen 2.5-coder (7B) full precision', 'Qwen 2.5 (32B) full precision', 'Qwen 2.5 (72B) quantized 4bit', 'Qwen 2.5 (72B) quantized 8bit', 'Codellama (7B) full precision', 'Codellama (13B) full precision', 'Codellama (34B) full precision', 'Codellama (70B) full precision', 'LLaMA 3.1 (8B) full precision', 'LLaMA 3.1 (70B) quantized 4bit', 'LLaMA 3.1 (70B) quantized 8bit', 'StarCoder2 (3B) full precision', 'StarCoder2 (7B) full precision', 'StarCoder2 (15B) full precision', 'Mistral (7B) full precision', 'OpenAI GPT4o']
2024-10-18 12:27:46,693:INFO:Selected model: Qwen 2.5-coder (7B) quantized 4bit
2024-10-18 12:27:47,996:INFO:Parameters for model Qwen 2.5-coder (7B) quantized 4bit configured successfully.
2024-10-18 12:27:47,996:WARNING:Synthetic data file not found: [Errno 2] No such file or directory: 'data/sensors/augmented_examples.json'. Continuing without synthetic data.
2024-10-18 12:27:47,997:WARNING:No specific configuration found for model Qwen 2.5-coder quantized 4bit. Using default settings.
2024-10-18 12:27:47,997:ERROR:Unexpected error in __main__.deploy_selected_model: name 'model_parameters' is not defined
2024-10-18 12:27:47,998:ERROR:Traceback: Traceback (most recent call last):
  File "/Users/lucasala/Documents/Projects/Maktaba/text-to-DSL/main.py", line 41, in deploy_selected_model
    if test_model(dataset_name, selected_model_name, system_prompt_version):
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/lucasala/Documents/Projects/Maktaba/text-to-DSL/scripts/model_testing.py", line 99, in test_model
    logging.info(f"Testing model {model_name} with {len(data_to_test)} examples and parameters: {model_parameters}.")
                                                                                                 ^^^^^^^^^^^^^^^^
NameError: name 'model_parameters' is not defined. Did you mean: 'model_patameters'?

2024-10-18 12:27:47,998:INFO:Process completed successfully.
2024-10-18 12:28:31,704:INFO:Starting the pipeline with the following steps: ['data_validation', 'configure_prompt_version', 'test_model', 'analyze_results', 'manage_experiment_logs', 'generate_visualizations']
2024-10-18 12:28:31,704:INFO:Starting data validation...
2024-10-18 12:28:32,600:INFO:Simple examples loaded successfully.
2024-10-18 12:28:32,600:INFO:Complex examples loaded successfully.
2024-10-18 12:28:32,646:INFO:Data validation completed successfully. All entries conform to the schema.
2024-10-18 12:28:32,647:INFO:Updating prompt versions...
2024-10-18 12:28:32,921:INFO:Deploying models...
2024-10-18 12:28:32,923:INFO:Available supported models: ['Qwen 2.5-coder (7B) quantized 4bit', 'Qwen 2.5-coder (7B) full precision', 'Qwen 2.5 (32B) full precision', 'Qwen 2.5 (72B) quantized 4bit', 'Qwen 2.5 (72B) quantized 8bit', 'Codellama (7B) full precision', 'Codellama (13B) full precision', 'Codellama (34B) full precision', 'Codellama (70B) full precision', 'LLaMA 3.1 (8B) full precision', 'LLaMA 3.1 (70B) quantized 4bit', 'LLaMA 3.1 (70B) quantized 8bit', 'StarCoder2 (3B) full precision', 'StarCoder2 (7B) full precision', 'StarCoder2 (15B) full precision', 'Mistral (7B) full precision', 'OpenAI GPT4o']
2024-10-18 12:28:33,236:INFO:Selected model: Qwen 2.5-coder (7B) quantized 4bit
2024-10-18 12:28:34,928:INFO:Parameters for model Qwen 2.5-coder (7B) quantized 4bit configured successfully.
2024-10-18 12:28:34,929:WARNING:Synthetic data file not found: [Errno 2] No such file or directory: 'data/sensors/augmented_examples.json'. Continuing without synthetic data.
2024-10-18 12:28:34,929:WARNING:No specific configuration found for model Qwen 2.5-coder quantized 4bit. Using default settings.
2024-10-18 12:28:34,929:INFO:Testing model Qwen 2.5-coder quantized 4bit with 4 examples and parameters: {}.
2024-10-18 12:28:34,929:ERROR:Unexpected error in __main__.deploy_selected_model: cannot access local variable 'file' where it is not associated with a value
2024-10-18 12:28:34,930:ERROR:Traceback: Traceback (most recent call last):
  File "/Users/lucasala/Documents/Projects/Maktaba/text-to-DSL/main.py", line 41, in deploy_selected_model
    if test_model(dataset_name, selected_model_name, system_prompt_version):
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/lucasala/Documents/Projects/Maktaba/text-to-DSL/scripts/model_testing.py", line 111, in test_model
    system_prompts = json.load(file)
                               ^^^^
UnboundLocalError: cannot access local variable 'file' where it is not associated with a value

2024-10-18 12:28:34,930:INFO:Process completed successfully.
2024-10-18 12:36:16,486:INFO:Starting the pipeline with the following steps: ['data_validation', 'configure_prompt_version', 'test_model', 'analyze_results', 'manage_experiment_logs', 'generate_visualizations']
2024-10-18 12:36:16,487:INFO:Starting data validation...
2024-10-18 12:36:17,463:INFO:Simple examples loaded successfully.
2024-10-18 12:36:17,463:INFO:Complex examples loaded successfully.
2024-10-18 12:36:17,509:INFO:Data validation completed successfully. All entries conform to the schema.
2024-10-18 12:36:17,509:INFO:Updating prompt versions...
2024-10-18 12:36:17,839:INFO:Deploying models...
2024-10-18 12:36:17,841:INFO:Available supported models: ['Qwen 2.5-coder (7B) quantized 4bit', 'Qwen 2.5-coder (7B) full precision', 'Qwen 2.5 (32B) full precision', 'Qwen 2.5 (72B) quantized 4bit', 'Qwen 2.5 (72B) quantized 8bit', 'Codellama (7B) full precision', 'Codellama (13B) full precision', 'Codellama (34B) full precision', 'Codellama (70B) full precision', 'LLaMA 3.1 (8B) full precision', 'LLaMA 3.1 (70B) quantized 4bit', 'LLaMA 3.1 (70B) quantized 8bit', 'StarCoder2 (3B) full precision', 'StarCoder2 (7B) full precision', 'StarCoder2 (15B) full precision', 'Mistral (7B) full precision', 'OpenAI GPT4o']
2024-10-18 12:36:18,330:INFO:Selected model: Qwen 2.5-coder (7B) quantized 4bit
2024-10-18 12:36:19,108:INFO:Parameters for model Qwen 2.5-coder (7B) quantized 4bit configured successfully.
2024-10-18 12:36:19,109:WARNING:Synthetic data file not found: [Errno 2] No such file or directory: 'data/sensors/augmented_examples.json'. Continuing without synthetic data.
2024-10-18 12:36:19,110:WARNING:No specific configuration found for model Qwen 2.5-coder quantized 4bit. Using default settings.
2024-10-18 12:36:19,110:INFO:Testing model Qwen 2.5-coder quantized 4bit with 4 examples and parameters: {}.
2024-10-18 12:36:19,110:WARNING:System prompt version {'version': '1.0', 'prompt': 'You are a helpful assistant.', 'rationale': 'Basic system prompt', 'timestamp': '2024-10-10T10:00:00'} not found. Defaulting to version 1.0.
2024-10-18 12:36:19,110:ERROR:Unexpected error in __main__.deploy_selected_model: 'system_prompt'
2024-10-18 12:36:19,111:ERROR:Traceback: Traceback (most recent call last):
  File "/Users/lucasala/Documents/Projects/Maktaba/text-to-DSL/main.py", line 41, in deploy_selected_model
    if test_model(dataset_name, selected_model_name, system_prompt_version):
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/lucasala/Documents/Projects/Maktaba/text-to-DSL/scripts/model_testing.py", line 145, in test_model
    system_prompt = next((sp['system_prompt'] for sp in system_prompts if sp['version'] == "1.0"), "")
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/lucasala/Documents/Projects/Maktaba/text-to-DSL/scripts/model_testing.py", line 145, in <genexpr>
    system_prompt = next((sp['system_prompt'] for sp in system_prompts if sp['version'] == "1.0"), "")
                          ~~^^^^^^^^^^^^^^^^^
KeyError: 'system_prompt'

2024-10-18 12:36:19,112:INFO:Process completed successfully.
2024-10-18 12:38:42,987:INFO:Starting the pipeline with the following steps: ['data_validation', 'configure_prompt_version', 'test_model', 'analyze_results', 'manage_experiment_logs', 'generate_visualizations']
2024-10-18 12:38:42,987:INFO:Starting data validation...
2024-10-18 12:38:43,999:INFO:Simple examples loaded successfully.
2024-10-18 12:38:43,999:INFO:Complex examples loaded successfully.
2024-10-18 12:38:44,043:INFO:Data validation completed successfully. All entries conform to the schema.
2024-10-18 12:38:44,043:INFO:Updating prompt versions...
2024-10-18 12:38:44,427:INFO:Deploying models...
2024-10-18 12:38:44,430:INFO:Available supported models: ['Qwen 2.5-coder (7B) quantized 4bit', 'Qwen 2.5-coder (7B) full precision', 'Qwen 2.5 (32B) full precision', 'Qwen 2.5 (72B) quantized 4bit', 'Qwen 2.5 (72B) quantized 8bit', 'Codellama (7B) full precision', 'Codellama (13B) full precision', 'Codellama (34B) full precision', 'Codellama (70B) full precision', 'LLaMA 3.1 (8B) full precision', 'LLaMA 3.1 (70B) quantized 4bit', 'LLaMA 3.1 (70B) quantized 8bit', 'StarCoder2 (3B) full precision', 'StarCoder2 (7B) full precision', 'StarCoder2 (15B) full precision', 'Mistral (7B) full precision', 'OpenAI GPT4o']
2024-10-18 12:38:44,787:INFO:Selected model: Qwen 2.5-coder (7B) quantized 4bit
2024-10-18 12:38:45,379:INFO:Parameters for model Qwen 2.5-coder (7B) quantized 4bit configured successfully.
2024-10-18 12:38:45,380:WARNING:Synthetic data file not found: [Errno 2] No such file or directory: 'data/sensors/augmented_examples.json'. Continuing without synthetic data.
2024-10-18 12:38:45,380:WARNING:No specific configuration found for model Qwen 2.5-coder quantized 4bit. Using default settings.
2024-10-18 12:38:45,380:INFO:Testing model Qwen 2.5-coder quantized 4bit with 4 examples and parameters: {}.
2024-10-18 12:38:45,380:WARNING:System prompt version {'version': '1.0', 'prompt': 'You are a helpful assistant.', 'rationale': 'Basic system prompt', 'timestamp': '2024-10-10T10:00:00'} not found. Defaulting to version 1.0.
2024-10-18 12:38:45,380:INFO:Using system prompt: You are a helpful assistant.
2024-10-18 12:38:45,380:ERROR:Grammar for sensors dataset not found.
2024-10-18 12:38:45,380:ERROR:Model Qwen 2.5-coder quantized 4bit failed testing.
2024-10-18 12:38:45,380:INFO:Process completed successfully.
2024-10-18 12:40:19,582:INFO:Starting the pipeline with the following steps: ['data_validation', 'configure_prompt_version', 'test_model', 'analyze_results', 'manage_experiment_logs', 'generate_visualizations']
2024-10-18 12:40:19,583:INFO:Starting data validation...
2024-10-18 12:40:20,140:INFO:Simple examples loaded successfully.
2024-10-18 12:40:20,141:INFO:Complex examples loaded successfully.
2024-10-18 12:40:20,186:INFO:Data validation completed successfully. All entries conform to the schema.
2024-10-18 12:40:20,186:INFO:Updating prompt versions...
2024-10-18 12:40:20,400:INFO:Deploying models...
2024-10-18 12:40:20,402:INFO:Available supported models: ['Qwen 2.5-coder (7B) quantized 4bit', 'Qwen 2.5-coder (7B) full precision', 'Qwen 2.5 (32B) full precision', 'Qwen 2.5 (72B) quantized 4bit', 'Qwen 2.5 (72B) quantized 8bit', 'Codellama (7B) full precision', 'Codellama (13B) full precision', 'Codellama (34B) full precision', 'Codellama (70B) full precision', 'LLaMA 3.1 (8B) full precision', 'LLaMA 3.1 (70B) quantized 4bit', 'LLaMA 3.1 (70B) quantized 8bit', 'StarCoder2 (3B) full precision', 'StarCoder2 (7B) full precision', 'StarCoder2 (15B) full precision', 'Mistral (7B) full precision', 'OpenAI GPT4o']
2024-10-18 12:40:20,689:INFO:Selected model: Qwen 2.5-coder (7B) quantized 4bit
2024-10-18 12:40:21,082:INFO:Parameters for model Qwen 2.5-coder (7B) quantized 4bit configured successfully.
2024-10-18 12:40:21,083:WARNING:Synthetic data file not found: [Errno 2] No such file or directory: 'data/sensors/augmented_examples.json'. Continuing without synthetic data.
2024-10-18 12:40:21,083:WARNING:No specific configuration found for model Qwen 2.5-coder quantized 4bit. Using default settings.
2024-10-18 12:40:21,083:INFO:Testing model Qwen 2.5-coder quantized 4bit with 4 examples and parameters: {}.
2024-10-18 12:40:21,083:WARNING:System prompt version {'version': '1.0', 'prompt': 'You are a helpful assistant.', 'rationale': 'Basic system prompt', 'timestamp': '2024-10-10T10:00:00'} not found. Defaulting to version 1.0.
2024-10-18 12:40:21,083:INFO:Using system prompt: You are a helpful assistant.
2024-10-18 12:40:21,083:ERROR:Grammar file sensors/grammar.txt not found: [Errno 2] No such file or directory: 'sensors/grammar.txt'
2024-10-18 12:40:21,084:ERROR:Traceback: Traceback (most recent call last):
  File "/Users/lucasala/Documents/Projects/Maktaba/text-to-DSL/scripts/model_testing.py", line 168, in test_model
    with open(grammar_file, 'r') as file:
         ^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'sensors/grammar.txt'

2024-10-18 12:40:21,085:ERROR:Model Qwen 2.5-coder quantized 4bit failed testing.
2024-10-18 12:40:21,085:INFO:Process completed successfully.
2024-10-18 12:41:06,610:INFO:Starting the pipeline with the following steps: ['data_validation', 'configure_prompt_version', 'test_model', 'analyze_results', 'manage_experiment_logs', 'generate_visualizations']
2024-10-18 12:41:06,611:INFO:Starting data validation...
2024-10-18 12:41:07,465:INFO:Simple examples loaded successfully.
2024-10-18 12:41:07,466:INFO:Complex examples loaded successfully.
2024-10-18 12:41:07,512:INFO:Data validation completed successfully. All entries conform to the schema.
2024-10-18 12:41:07,512:INFO:Updating prompt versions...
2024-10-18 12:41:07,734:INFO:Deploying models...
2024-10-18 12:41:07,736:INFO:Available supported models: ['Qwen 2.5-coder (7B) quantized 4bit', 'Qwen 2.5-coder (7B) full precision', 'Qwen 2.5 (32B) full precision', 'Qwen 2.5 (72B) quantized 4bit', 'Qwen 2.5 (72B) quantized 8bit', 'Codellama (7B) full precision', 'Codellama (13B) full precision', 'Codellama (34B) full precision', 'Codellama (70B) full precision', 'LLaMA 3.1 (8B) full precision', 'LLaMA 3.1 (70B) quantized 4bit', 'LLaMA 3.1 (70B) quantized 8bit', 'StarCoder2 (3B) full precision', 'StarCoder2 (7B) full precision', 'StarCoder2 (15B) full precision', 'Mistral (7B) full precision', 'OpenAI GPT4o']
2024-10-18 12:41:08,114:INFO:Selected model: Qwen 2.5-coder (7B) quantized 4bit
2024-10-18 12:41:08,486:INFO:Parameters for model Qwen 2.5-coder (7B) quantized 4bit configured successfully.
2024-10-18 12:41:08,487:WARNING:Synthetic data file not found: [Errno 2] No such file or directory: 'data/sensors/augmented_examples.json'. Continuing without synthetic data.
2024-10-18 12:41:08,487:WARNING:No specific configuration found for model Qwen 2.5-coder quantized 4bit. Using default settings.
2024-10-18 12:41:08,487:INFO:Testing model Qwen 2.5-coder quantized 4bit with 4 examples and parameters: {}.
2024-10-18 12:41:08,487:WARNING:System prompt version {'version': '1.0', 'prompt': 'You are a helpful assistant.', 'rationale': 'Basic system prompt', 'timestamp': '2024-10-10T10:00:00'} not found. Defaulting to version 1.0.
2024-10-18 12:41:08,487:INFO:Using system prompt: You are a helpful assistant.
2024-10-18 12:41:08,488:INFO:Grammar for sensors loaded successfully.
2024-10-18 12:41:08,488:INFO:Using grammar: I need you to use this grammar for a set of instructions that I will be giving you:

root ::= parse
parse ::= sentence+
sentence ::= createStatement
createStatement ::= "CREATE " (createProduct | createRange | createDimension | createSensor)
createProduct ::= "PRODUCT " identifier " USING " srid ";\n\n"
createRange ::= "RANGE " identifier " (\n" rangeProperty (",\n" rangeProperty)* "\n)" ";\n\n"
rangeProperty ::= rangeNumber (" TO " rangeNumber)? " AS " text (" COLOR " hexColor)? | " DEFAULT " "AS " text (" COLOR " hexColor)?
rangeNumber ::= identifier | floatNumber | intNumber | "INFINITY" | "-INFINITY"
createDimension ::= createSpatialDimension | createCategoricalDimension
createSpatialDimension ::= "SPATIAL DIMENSION " identifier " (\n" "\tgeometry" ":" (type | " Geometry") "\n)" createDimensionProperties createParentDimension? ";\n\n"
createCategoricalDimension ::= "CATEGORICAL DIMENSION " identifier " (\n" "FIELD" ":" identifier ")" ";\n\n"
createParentDimension ::= " WITH PARENT " "(\n" identifier (",\n" identifier)* "\n)"
createDimensionProperties ::= " WITH PROPERTIES " "(\n" dimPropertyDefinition (",\n" dimPropertyDefinition)* "\n)"
dimPropertyDefinition ::= "\t" identifier type
createSensor ::= "SENSOR " identifier " (\n" "\tinterval" ": " intNumber ",\n" "\tdatasource" ": " dataSource ",\n" "\tgeometry" ":" type "\n)" createSensorProperties createSensorMeasurementData (addSpatialDimensionToSensor)* (addCategoricalDimensionToSensor)? (addBBXToSensor)? ";\n\n"
createSensorProperties ::= " WITH PROPERTIES " "(\n" sensorPropertyDefinition (",\n" sensorPropertyDefinition)* "\n)"
sensorPropertyDefinition ::= "\t" identifier type
createSensorMeasurementData ::= " WITH MEASUREMENT DATA " "(\n" createMeasurementProperty (",\n" createMeasurementProperty)* "\n)"
createMeasurementProperty ::= "\t" identifier type (" UNITS " text)? (" ICON " text)? (" RANGE " identifier)?
addSpatialDimensionToSensor ::= " WITH SPATIAL DIMENSIONS " identifier "(\n" "\t" identifier (",\n" "\t" identifier)* "\n)"
addCategoricalDimensionToSensor ::= " WITH CATEGORICAL DIMENSIONS " "(\n" "\t" identifier (" RANGE " identifier)? (",\n" "\t" identifier (" RANGE " identifier)?)* "\n)"
addBBXToSensor ::= " WITH BBOX " "(" ("[")? coordinate ("]")? ", " intNumber")"
srid ::= intNumber
identifier ::= text
text ::= [a-zA-Z] [a-zA-Z]? [a-zA-Z]? [a-zA-Z]? [a-zA-Z]? [a-zA-Z]? [a-zA-Z]? [a-zA-Z]? [a-zA-Z]? [a-zA-Z]?
quotedText ::= "\"" text "\""
ws ::= ([ \t\n] ws)?
type ::= " Long" | " Boolean" | " Float" | " Integer" | " Double" | " Localdate" | " String" | " Datetime" | " Linestring" | " Multilinestring" | " Polygon" | " Multipolygon" | " Point" | " Multipoint"
dataSource ::= "postgres" | "elasticsearch"
hexColor ::= "#" [0-9a-fA-F] [0-9a-fA-F] [0-9a-fA-F] [0-9a-fA-F] [0-9a-fA-F] [0-9a-fA-F]
digit ::= [0-9]
digits ::= digit+
intNumber ::= digits
floatNumber ::= (digits? ".")? digits
negativeFloat ::= ("-")? floatNumber
coordinate ::= negativeFloat ", " negativeFloat

2024-10-18 12:41:08,489:ERROR:few_shot_example.json for sensors dataset not found.
2024-10-18 12:41:08,489:ERROR:Unexpected error in __main__.deploy_selected_model: name 'prompt' is not defined
2024-10-18 12:41:08,493:ERROR:Traceback: Traceback (most recent call last):
  File "/Users/lucasala/Documents/Projects/Maktaba/text-to-DSL/scripts/model_testing.py", line 202, in test_model
    response = client.chat.completions.create(
               ^^^^^^
NameError: name 'client' is not defined

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/lucasala/Documents/Projects/Maktaba/text-to-DSL/main.py", line 41, in deploy_selected_model
    if test_model(dataset_name, selected_model_name, system_prompt_version):
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/lucasala/Documents/Projects/Maktaba/text-to-DSL/scripts/model_testing.py", line 213, in test_model
    logging.warning(f"Attempt {attempt + 1} failed for model {model_name} on input '{prompt}': {e}")
                                                                                     ^^^^^^
NameError: name 'prompt' is not defined

2024-10-18 12:41:08,493:INFO:Process completed successfully.
2024-10-18 12:42:51,252:INFO:Starting the pipeline with the following steps: ['data_validation', 'configure_prompt_version', 'test_model', 'analyze_results', 'manage_experiment_logs', 'generate_visualizations']
2024-10-18 12:42:51,252:INFO:Starting data validation...
2024-10-18 12:42:52,127:INFO:Simple examples loaded successfully.
2024-10-18 12:42:52,128:INFO:Complex examples loaded successfully.
2024-10-18 12:42:52,175:INFO:Data validation completed successfully. All entries conform to the schema.
2024-10-18 12:42:52,175:INFO:Updating prompt versions...
2024-10-18 12:42:52,397:INFO:Deploying models...
2024-10-18 12:42:52,399:INFO:Available supported models: ['Qwen 2.5-coder (7B) quantized 4bit', 'Qwen 2.5-coder (7B) full precision', 'Qwen 2.5 (32B) full precision', 'Qwen 2.5 (72B) quantized 4bit', 'Qwen 2.5 (72B) quantized 8bit', 'Codellama (7B) full precision', 'Codellama (13B) full precision', 'Codellama (34B) full precision', 'Codellama (70B) full precision', 'LLaMA 3.1 (8B) full precision', 'LLaMA 3.1 (70B) quantized 4bit', 'LLaMA 3.1 (70B) quantized 8bit', 'StarCoder2 (3B) full precision', 'StarCoder2 (7B) full precision', 'StarCoder2 (15B) full precision', 'Mistral (7B) full precision', 'OpenAI GPT4o']
2024-10-18 12:42:52,905:INFO:Selected model: Qwen 2.5-coder (7B) quantized 4bit
2024-10-18 12:42:53,482:INFO:Parameters for model Qwen 2.5-coder (7B) quantized 4bit configured successfully.
2024-10-18 12:42:53,483:WARNING:Synthetic data file not found: [Errno 2] No such file or directory: 'data/sensors/augmented_examples.json'. Continuing without synthetic data.
2024-10-18 12:42:53,483:WARNING:No specific configuration found for model Qwen 2.5-coder quantized 4bit. Using default settings.
2024-10-18 12:42:53,483:INFO:Testing model Qwen 2.5-coder quantized 4bit with 4 examples and parameters: {}.
2024-10-18 12:42:53,483:WARNING:System prompt version {'version': '1.0', 'prompt': 'You are a helpful assistant.', 'rationale': 'Basic system prompt', 'timestamp': '2024-10-10T10:00:00'} not found. Defaulting to version 1.0.
2024-10-18 12:42:53,483:INFO:Using system prompt: You are a helpful assistant.
2024-10-18 12:42:53,484:INFO:Grammar for sensors loaded successfully.
2024-10-18 12:42:53,484:INFO:Using grammar: I need you to use this grammar for a set of instructions that I will be giving you:

root ::= parse
parse ::= sentence+
sentence ::= createStatement
createStatement ::= "CREATE " (createProduct | createRange | createDimension | createSensor)
createProduct ::= "PRODUCT " identifier " USING " srid ";\n\n"
createRange ::= "RANGE " identifier " (\n" rangeProperty (",\n" rangeProperty)* "\n)" ";\n\n"
rangeProperty ::= rangeNumber (" TO " rangeNumber)? " AS " text (" COLOR " hexColor)? | " DEFAULT " "AS " text (" COLOR " hexColor)?
rangeNumber ::= identifier | floatNumber | intNumber | "INFINITY" | "-INFINITY"
createDimension ::= createSpatialDimension | createCategoricalDimension
createSpatialDimension ::= "SPATIAL DIMENSION " identifier " (\n" "\tgeometry" ":" (type | " Geometry") "\n)" createDimensionProperties createParentDimension? ";\n\n"
createCategoricalDimension ::= "CATEGORICAL DIMENSION " identifier " (\n" "FIELD" ":" identifier ")" ";\n\n"
createParentDimension ::= " WITH PARENT " "(\n" identifier (",\n" identifier)* "\n)"
createDimensionProperties ::= " WITH PROPERTIES " "(\n" dimPropertyDefinition (",\n" dimPropertyDefinition)* "\n)"
dimPropertyDefinition ::= "\t" identifier type
createSensor ::= "SENSOR " identifier " (\n" "\tinterval" ": " intNumber ",\n" "\tdatasource" ": " dataSource ",\n" "\tgeometry" ":" type "\n)" createSensorProperties createSensorMeasurementData (addSpatialDimensionToSensor)* (addCategoricalDimensionToSensor)? (addBBXToSensor)? ";\n\n"
createSensorProperties ::= " WITH PROPERTIES " "(\n" sensorPropertyDefinition (",\n" sensorPropertyDefinition)* "\n)"
sensorPropertyDefinition ::= "\t" identifier type
createSensorMeasurementData ::= " WITH MEASUREMENT DATA " "(\n" createMeasurementProperty (",\n" createMeasurementProperty)* "\n)"
createMeasurementProperty ::= "\t" identifier type (" UNITS " text)? (" ICON " text)? (" RANGE " identifier)?
addSpatialDimensionToSensor ::= " WITH SPATIAL DIMENSIONS " identifier "(\n" "\t" identifier (",\n" "\t" identifier)* "\n)"
addCategoricalDimensionToSensor ::= " WITH CATEGORICAL DIMENSIONS " "(\n" "\t" identifier (" RANGE " identifier)? (",\n" "\t" identifier (" RANGE " identifier)?)* "\n)"
addBBXToSensor ::= " WITH BBOX " "(" ("[")? coordinate ("]")? ", " intNumber")"
srid ::= intNumber
identifier ::= text
text ::= [a-zA-Z] [a-zA-Z]? [a-zA-Z]? [a-zA-Z]? [a-zA-Z]? [a-zA-Z]? [a-zA-Z]? [a-zA-Z]? [a-zA-Z]? [a-zA-Z]?
quotedText ::= "\"" text "\""
ws ::= ([ \t\n] ws)?
type ::= " Long" | " Boolean" | " Float" | " Integer" | " Double" | " Localdate" | " String" | " Datetime" | " Linestring" | " Multilinestring" | " Polygon" | " Multipolygon" | " Point" | " Multipoint"
dataSource ::= "postgres" | "elasticsearch"
hexColor ::= "#" [0-9a-fA-F] [0-9a-fA-F] [0-9a-fA-F] [0-9a-fA-F] [0-9a-fA-F] [0-9a-fA-F]
digit ::= [0-9]
digits ::= digit+
intNumber ::= digits
floatNumber ::= (digits? ".")? digits
negativeFloat ::= ("-")? floatNumber
coordinate ::= negativeFloat ", " negativeFloat

2024-10-18 12:42:53,484:ERROR:few_shot_example.json for sensors dataset not found.
2024-10-18 12:42:53,485:ERROR:Unexpected error in __main__.deploy_selected_model: cannot access local variable 'few_shot_examples' where it is not associated with a value
2024-10-18 12:42:53,486:ERROR:Traceback: Traceback (most recent call last):
  File "/Users/lucasala/Documents/Projects/Maktaba/text-to-DSL/main.py", line 41, in deploy_selected_model
    if test_model(dataset_name, selected_model_name, system_prompt_version):
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/lucasala/Documents/Projects/Maktaba/text-to-DSL/scripts/model_testing.py", line 197, in test_model
    message = build_message(model_name, system_prompt, grammar, few_shot_examples, example)
                                                                ^^^^^^^^^^^^^^^^^
UnboundLocalError: cannot access local variable 'few_shot_examples' where it is not associated with a value

2024-10-18 12:42:53,486:INFO:Process completed successfully.
2024-10-18 12:47:19,363:INFO:Starting the pipeline with the following steps: ['data_validation', 'configure_prompt_version', 'test_model', 'analyze_results', 'manage_experiment_logs', 'generate_visualizations']
2024-10-18 12:47:19,364:INFO:Starting data validation...
2024-10-18 12:47:19,997:INFO:Simple examples loaded successfully.
2024-10-18 12:47:19,997:INFO:Complex examples loaded successfully.
2024-10-18 12:47:20,044:INFO:Data validation completed successfully. All entries conform to the schema.
2024-10-18 12:47:20,044:INFO:Updating prompt versions...
2024-10-18 12:47:20,258:INFO:Deploying models...
2024-10-18 12:47:20,260:INFO:Available supported models: ['Qwen 2.5-coder (7B) quantized 4bit', 'Qwen 2.5-coder (7B) full precision', 'Qwen 2.5 (32B) full precision', 'Qwen 2.5 (72B) quantized 4bit', 'Qwen 2.5 (72B) quantized 8bit', 'Codellama (7B) full precision', 'Codellama (13B) full precision', 'Codellama (34B) full precision', 'Codellama (70B) full precision', 'LLaMA 3.1 (8B) full precision', 'LLaMA 3.1 (70B) quantized 4bit', 'LLaMA 3.1 (70B) quantized 8bit', 'StarCoder2 (3B) full precision', 'StarCoder2 (7B) full precision', 'StarCoder2 (15B) full precision', 'Mistral (7B) full precision', 'OpenAI GPT4o']
2024-10-18 12:47:20,491:INFO:Selected model: Qwen 2.5-coder (7B) quantized 4bit
2024-10-18 12:47:20,994:INFO:Parameters for model Qwen 2.5-coder (7B) quantized 4bit configured successfully.
2024-10-18 12:47:20,995:WARNING:Synthetic data file not found: [Errno 2] No such file or directory: 'data/sensors/augmented_examples.json'. Continuing without synthetic data.
2024-10-18 12:47:20,996:WARNING:No specific configuration found for model Qwen 2.5-coder quantized 4bit. Using default settings.
2024-10-18 12:47:20,996:INFO:Testing model Qwen 2.5-coder quantized 4bit with 4 examples and parameters: {}.
2024-10-18 12:47:20,996:WARNING:System prompt version {'version': '1.0', 'prompt': 'You are a helpful assistant.', 'rationale': 'Basic system prompt', 'timestamp': '2024-10-10T10:00:00'} not found. Defaulting to version 1.0.
2024-10-18 12:47:20,996:INFO:Using system prompt: You are a helpful assistant.
2024-10-18 12:47:20,997:INFO:Grammar for sensors loaded successfully.
2024-10-18 12:47:20,997:INFO:Using grammar: I need you to use this grammar for a set of instructions that I will be giving you:

root ::= parse
parse ::= sentence+
sentence ::= createStatement
createStatement ::= "CREATE " (createProduct | createRange | createDimension | createSensor)
createProduct ::= "PRODUCT " identifier " USING " srid ";\n\n"
createRange ::= "RANGE " identifier " (\n" rangeProperty (",\n" rangeProperty)* "\n)" ";\n\n"
rangeProperty ::= rangeNumber (" TO " rangeNumber)? " AS " text (" COLOR " hexColor)? | " DEFAULT " "AS " text (" COLOR " hexColor)?
rangeNumber ::= identifier | floatNumber | intNumber | "INFINITY" | "-INFINITY"
createDimension ::= createSpatialDimension | createCategoricalDimension
createSpatialDimension ::= "SPATIAL DIMENSION " identifier " (\n" "\tgeometry" ":" (type | " Geometry") "\n)" createDimensionProperties createParentDimension? ";\n\n"
createCategoricalDimension ::= "CATEGORICAL DIMENSION " identifier " (\n" "FIELD" ":" identifier ")" ";\n\n"
createParentDimension ::= " WITH PARENT " "(\n" identifier (",\n" identifier)* "\n)"
createDimensionProperties ::= " WITH PROPERTIES " "(\n" dimPropertyDefinition (",\n" dimPropertyDefinition)* "\n)"
dimPropertyDefinition ::= "\t" identifier type
createSensor ::= "SENSOR " identifier " (\n" "\tinterval" ": " intNumber ",\n" "\tdatasource" ": " dataSource ",\n" "\tgeometry" ":" type "\n)" createSensorProperties createSensorMeasurementData (addSpatialDimensionToSensor)* (addCategoricalDimensionToSensor)? (addBBXToSensor)? ";\n\n"
createSensorProperties ::= " WITH PROPERTIES " "(\n" sensorPropertyDefinition (",\n" sensorPropertyDefinition)* "\n)"
sensorPropertyDefinition ::= "\t" identifier type
createSensorMeasurementData ::= " WITH MEASUREMENT DATA " "(\n" createMeasurementProperty (",\n" createMeasurementProperty)* "\n)"
createMeasurementProperty ::= "\t" identifier type (" UNITS " text)? (" ICON " text)? (" RANGE " identifier)?
addSpatialDimensionToSensor ::= " WITH SPATIAL DIMENSIONS " identifier "(\n" "\t" identifier (",\n" "\t" identifier)* "\n)"
addCategoricalDimensionToSensor ::= " WITH CATEGORICAL DIMENSIONS " "(\n" "\t" identifier (" RANGE " identifier)? (",\n" "\t" identifier (" RANGE " identifier)?)* "\n)"
addBBXToSensor ::= " WITH BBOX " "(" ("[")? coordinate ("]")? ", " intNumber")"
srid ::= intNumber
identifier ::= text
text ::= [a-zA-Z] [a-zA-Z]? [a-zA-Z]? [a-zA-Z]? [a-zA-Z]? [a-zA-Z]? [a-zA-Z]? [a-zA-Z]? [a-zA-Z]? [a-zA-Z]?
quotedText ::= "\"" text "\""
ws ::= ([ \t\n] ws)?
type ::= " Long" | " Boolean" | " Float" | " Integer" | " Double" | " Localdate" | " String" | " Datetime" | " Linestring" | " Multilinestring" | " Polygon" | " Multipolygon" | " Point" | " Multipoint"
dataSource ::= "postgres" | "elasticsearch"
hexColor ::= "#" [0-9a-fA-F] [0-9a-fA-F] [0-9a-fA-F] [0-9a-fA-F] [0-9a-fA-F] [0-9a-fA-F]
digit ::= [0-9]
digits ::= digit+
intNumber ::= digits
floatNumber ::= (digits? ".")? digits
negativeFloat ::= ("-")? floatNumber
coordinate ::= negativeFloat ", " negativeFloat

2024-10-18 12:47:20,998:WARNING:Few-shot examples file sensors/few_shot_examples.json not found: [Errno 2] No such file or directory: 'sensors/few_shot_examples.json'. Continuing without few-shot examples.
2024-10-18 12:47:20,998:ERROR:Unexpected error in __main__.deploy_selected_model: name 'prompt' is not defined
2024-10-18 12:47:21,002:ERROR:Traceback: Traceback (most recent call last):
  File "/Users/lucasala/Documents/Projects/Maktaba/text-to-DSL/scripts/model_testing.py", line 213, in test_model
    response = client.chat.completions.create(
               ^^^^^^
NameError: name 'client' is not defined

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/lucasala/Documents/Projects/Maktaba/text-to-DSL/main.py", line 41, in deploy_selected_model
    if test_model(dataset_name, selected_model_name, system_prompt_version):
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/lucasala/Documents/Projects/Maktaba/text-to-DSL/scripts/model_testing.py", line 224, in test_model
    logging.warning(f"Attempt {attempt + 1} failed for model {model_name} on input '{prompt}': {e}")
                                                                                     ^^^^^^
NameError: name 'prompt' is not defined

2024-10-18 12:47:21,003:INFO:Process completed successfully.
2024-10-18 12:49:54,901:INFO:Starting the pipeline with the following steps: ['data_validation', 'configure_prompt_version', 'test_model', 'analyze_results', 'manage_experiment_logs', 'generate_visualizations']
2024-10-18 12:49:54,902:INFO:Starting data validation...
2024-10-18 12:49:55,803:INFO:Simple examples loaded successfully.
2024-10-18 12:49:55,804:INFO:Complex examples loaded successfully.
2024-10-18 12:49:55,842:INFO:Data validation completed successfully. All entries conform to the schema.
2024-10-18 12:49:55,842:INFO:Updating prompt versions...
2024-10-18 12:49:56,076:INFO:Deploying models...
2024-10-18 12:49:56,078:INFO:Available supported models: ['Qwen 2.5-coder (7B) quantized 4bit', 'Qwen 2.5-coder (7B) full precision', 'Qwen 2.5 (32B) full precision', 'Qwen 2.5 (72B) quantized 4bit', 'Qwen 2.5 (72B) quantized 8bit', 'Codellama (7B) full precision', 'Codellama (13B) full precision', 'Codellama (34B) full precision', 'Codellama (70B) full precision', 'LLaMA 3.1 (8B) full precision', 'LLaMA 3.1 (70B) quantized 4bit', 'LLaMA 3.1 (70B) quantized 8bit', 'StarCoder2 (3B) full precision', 'StarCoder2 (7B) full precision', 'StarCoder2 (15B) full precision', 'Mistral (7B) full precision', 'OpenAI GPT4o']
2024-10-18 12:49:56,376:INFO:Selected model: Qwen 2.5-coder (7B) quantized 4bit
2024-10-18 12:49:56,940:INFO:Parameters for model Qwen 2.5-coder (7B) quantized 4bit configured successfully.
2024-10-18 12:49:56,941:WARNING:Synthetic data file not found: [Errno 2] No such file or directory: 'data/sensors/augmented_examples.json'. Continuing without synthetic data.
2024-10-18 12:49:56,941:WARNING:No specific configuration found for model Qwen 2.5-coder quantized 4bit. Using default settings.
2024-10-18 12:49:56,941:INFO:Testing model Qwen 2.5-coder quantized 4bit with 4 examples and parameters: {}.
2024-10-18 12:49:56,942:WARNING:System prompt version {'version': '1.0', 'prompt': 'You are a helpful assistant.', 'rationale': 'Basic system prompt', 'timestamp': '2024-10-10T10:00:00'} not found. Defaulting to version 1.0.
2024-10-18 12:49:56,942:INFO:Using system prompt: You are a helpful assistant.
2024-10-18 12:49:56,942:INFO:Grammar for sensors loaded successfully.
2024-10-18 12:49:56,942:INFO:Using grammar: I need you to use this grammar for a set of instructions that I will be giving you:

root ::= parse
parse ::= sentence+
sentence ::= createStatement
createStatement ::= "CREATE " (createProduct | createRange | createDimension | createSensor)
createProduct ::= "PRODUCT " identifier " USING " srid ";\n\n"
createRange ::= "RANGE " identifier " (\n" rangeProperty (",\n" rangeProperty)* "\n)" ";\n\n"
rangeProperty ::= rangeNumber (" TO " rangeNumber)? " AS " text (" COLOR " hexColor)? | " DEFAULT " "AS " text (" COLOR " hexColor)?
rangeNumber ::= identifier | floatNumber | intNumber | "INFINITY" | "-INFINITY"
createDimension ::= createSpatialDimension | createCategoricalDimension
createSpatialDimension ::= "SPATIAL DIMENSION " identifier " (\n" "\tgeometry" ":" (type | " Geometry") "\n)" createDimensionProperties createParentDimension? ";\n\n"
createCategoricalDimension ::= "CATEGORICAL DIMENSION " identifier " (\n" "FIELD" ":" identifier ")" ";\n\n"
createParentDimension ::= " WITH PARENT " "(\n" identifier (",\n" identifier)* "\n)"
createDimensionProperties ::= " WITH PROPERTIES " "(\n" dimPropertyDefinition (",\n" dimPropertyDefinition)* "\n)"
dimPropertyDefinition ::= "\t" identifier type
createSensor ::= "SENSOR " identifier " (\n" "\tinterval" ": " intNumber ",\n" "\tdatasource" ": " dataSource ",\n" "\tgeometry" ":" type "\n)" createSensorProperties createSensorMeasurementData (addSpatialDimensionToSensor)* (addCategoricalDimensionToSensor)? (addBBXToSensor)? ";\n\n"
createSensorProperties ::= " WITH PROPERTIES " "(\n" sensorPropertyDefinition (",\n" sensorPropertyDefinition)* "\n)"
sensorPropertyDefinition ::= "\t" identifier type
createSensorMeasurementData ::= " WITH MEASUREMENT DATA " "(\n" createMeasurementProperty (",\n" createMeasurementProperty)* "\n)"
createMeasurementProperty ::= "\t" identifier type (" UNITS " text)? (" ICON " text)? (" RANGE " identifier)?
addSpatialDimensionToSensor ::= " WITH SPATIAL DIMENSIONS " identifier "(\n" "\t" identifier (",\n" "\t" identifier)* "\n)"
addCategoricalDimensionToSensor ::= " WITH CATEGORICAL DIMENSIONS " "(\n" "\t" identifier (" RANGE " identifier)? (",\n" "\t" identifier (" RANGE " identifier)?)* "\n)"
addBBXToSensor ::= " WITH BBOX " "(" ("[")? coordinate ("]")? ", " intNumber")"
srid ::= intNumber
identifier ::= text
text ::= [a-zA-Z] [a-zA-Z]? [a-zA-Z]? [a-zA-Z]? [a-zA-Z]? [a-zA-Z]? [a-zA-Z]? [a-zA-Z]? [a-zA-Z]? [a-zA-Z]?
quotedText ::= "\"" text "\""
ws ::= ([ \t\n] ws)?
type ::= " Long" | " Boolean" | " Float" | " Integer" | " Double" | " Localdate" | " String" | " Datetime" | " Linestring" | " Multilinestring" | " Polygon" | " Multipolygon" | " Point" | " Multipoint"
dataSource ::= "postgres" | "elasticsearch"
hexColor ::= "#" [0-9a-fA-F] [0-9a-fA-F] [0-9a-fA-F] [0-9a-fA-F] [0-9a-fA-F] [0-9a-fA-F]
digit ::= [0-9]
digits ::= digit+
intNumber ::= digits
floatNumber ::= (digits? ".")? digits
negativeFloat ::= ("-")? floatNumber
coordinate ::= negativeFloat ", " negativeFloat

2024-10-18 12:49:56,942:WARNING:Few-shot examples file sensors/few_shot_examples.json not found: [Errno 2] No such file or directory: 'sensors/few_shot_examples.json'. Continuing without few-shot examples.
2024-10-18 12:49:56,943:ERROR:Unexpected error in __main__.deploy_selected_model: cannot access local variable 'message' where it is not associated with a value
2024-10-18 12:49:56,944:ERROR:Traceback: Traceback (most recent call last):
  File "/Users/lucasala/Documents/Projects/Maktaba/text-to-DSL/main.py", line 41, in deploy_selected_model
    if test_model(dataset_name, selected_model_name, system_prompt_version):
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/lucasala/Documents/Projects/Maktaba/text-to-DSL/scripts/model_testing.py", line 204, in test_model
    message = build_message(model_name, system_prompt, grammar, few_shot_examples, example)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/lucasala/Documents/Projects/Maktaba/text-to-DSL/scripts/message_builder.py", line 20, in build_message
    message += f"Rules that need to be followed to write the code:\n{grammar}\n\n"
    ^^^^^^^
UnboundLocalError: cannot access local variable 'message' where it is not associated with a value

2024-10-18 12:49:56,944:INFO:Process completed successfully.
2024-10-18 12:50:06,824:INFO:Starting the pipeline with the following steps: ['data_validation', 'configure_prompt_version', 'test_model', 'analyze_results', 'manage_experiment_logs', 'generate_visualizations']
2024-10-18 12:50:06,825:INFO:Starting data validation...
2024-10-18 12:50:07,383:INFO:Simple examples loaded successfully.
2024-10-18 12:50:07,384:INFO:Complex examples loaded successfully.
2024-10-18 12:50:07,419:INFO:Data validation completed successfully. All entries conform to the schema.
2024-10-18 12:50:07,419:INFO:Updating prompt versions...
2024-10-18 12:50:07,618:INFO:Deploying models...
2024-10-18 12:50:07,618:INFO:Available supported models: ['Qwen 2.5-coder (7B) quantized 4bit', 'Qwen 2.5-coder (7B) full precision', 'Qwen 2.5 (32B) full precision', 'Qwen 2.5 (72B) quantized 4bit', 'Qwen 2.5 (72B) quantized 8bit', 'Codellama (7B) full precision', 'Codellama (13B) full precision', 'Codellama (34B) full precision', 'Codellama (70B) full precision', 'LLaMA 3.1 (8B) full precision', 'LLaMA 3.1 (70B) quantized 4bit', 'LLaMA 3.1 (70B) quantized 8bit', 'StarCoder2 (3B) full precision', 'StarCoder2 (7B) full precision', 'StarCoder2 (15B) full precision', 'Mistral (7B) full precision', 'OpenAI GPT4o']
2024-10-18 12:50:08,020:INFO:Selected model: Qwen 2.5-coder (7B) quantized 4bit
2024-10-18 12:50:12,598:INFO:Parameters for model Qwen 2.5-coder (7B) quantized 4bit configured successfully.
2024-10-18 12:50:12,598:WARNING:Synthetic data file not found: [Errno 2] No such file or directory: 'data/sensors/augmented_examples.json'. Continuing without synthetic data.
2024-10-18 12:50:12,599:WARNING:No specific configuration found for model Qwen 2.5-coder quantized 4bit. Using default settings.
2024-10-18 12:50:12,599:INFO:Testing model Qwen 2.5-coder quantized 4bit with 4 examples and parameters: {}.
2024-10-18 12:50:12,599:WARNING:System prompt version {'version': '1.0', 'prompt': 'You are a helpful assistant.', 'rationale': 'Basic system prompt', 'timestamp': '2024-10-10T10:00:00'} not found. Defaulting to version 1.0.
2024-10-18 12:50:12,599:INFO:Using system prompt: You are a helpful assistant.
2024-10-18 12:50:12,616:INFO:Grammar for sensors loaded successfully.
2024-10-18 12:50:12,617:INFO:Using grammar: I need you to use this grammar for a set of instructions that I will be giving you:

root ::= parse
parse ::= sentence+
sentence ::= createStatement
createStatement ::= "CREATE " (createProduct | createRange | createDimension | createSensor)
createProduct ::= "PRODUCT " identifier " USING " srid ";\n\n"
createRange ::= "RANGE " identifier " (\n" rangeProperty (",\n" rangeProperty)* "\n)" ";\n\n"
rangeProperty ::= rangeNumber (" TO " rangeNumber)? " AS " text (" COLOR " hexColor)? | " DEFAULT " "AS " text (" COLOR " hexColor)?
rangeNumber ::= identifier | floatNumber | intNumber | "INFINITY" | "-INFINITY"
createDimension ::= createSpatialDimension | createCategoricalDimension
createSpatialDimension ::= "SPATIAL DIMENSION " identifier " (\n" "\tgeometry" ":" (type | " Geometry") "\n)" createDimensionProperties createParentDimension? ";\n\n"
createCategoricalDimension ::= "CATEGORICAL DIMENSION " identifier " (\n" "FIELD" ":" identifier ")" ";\n\n"
createParentDimension ::= " WITH PARENT " "(\n" identifier (",\n" identifier)* "\n)"
createDimensionProperties ::= " WITH PROPERTIES " "(\n" dimPropertyDefinition (",\n" dimPropertyDefinition)* "\n)"
dimPropertyDefinition ::= "\t" identifier type
createSensor ::= "SENSOR " identifier " (\n" "\tinterval" ": " intNumber ",\n" "\tdatasource" ": " dataSource ",\n" "\tgeometry" ":" type "\n)" createSensorProperties createSensorMeasurementData (addSpatialDimensionToSensor)* (addCategoricalDimensionToSensor)? (addBBXToSensor)? ";\n\n"
createSensorProperties ::= " WITH PROPERTIES " "(\n" sensorPropertyDefinition (",\n" sensorPropertyDefinition)* "\n)"
sensorPropertyDefinition ::= "\t" identifier type
createSensorMeasurementData ::= " WITH MEASUREMENT DATA " "(\n" createMeasurementProperty (",\n" createMeasurementProperty)* "\n)"
createMeasurementProperty ::= "\t" identifier type (" UNITS " text)? (" ICON " text)? (" RANGE " identifier)?
addSpatialDimensionToSensor ::= " WITH SPATIAL DIMENSIONS " identifier "(\n" "\t" identifier (",\n" "\t" identifier)* "\n)"
addCategoricalDimensionToSensor ::= " WITH CATEGORICAL DIMENSIONS " "(\n" "\t" identifier (" RANGE " identifier)? (",\n" "\t" identifier (" RANGE " identifier)?)* "\n)"
addBBXToSensor ::= " WITH BBOX " "(" ("[")? coordinate ("]")? ", " intNumber")"
srid ::= intNumber
identifier ::= text
text ::= [a-zA-Z] [a-zA-Z]? [a-zA-Z]? [a-zA-Z]? [a-zA-Z]? [a-zA-Z]? [a-zA-Z]? [a-zA-Z]? [a-zA-Z]? [a-zA-Z]?
quotedText ::= "\"" text "\""
ws ::= ([ \t\n] ws)?
type ::= " Long" | " Boolean" | " Float" | " Integer" | " Double" | " Localdate" | " String" | " Datetime" | " Linestring" | " Multilinestring" | " Polygon" | " Multipolygon" | " Point" | " Multipoint"
dataSource ::= "postgres" | "elasticsearch"
hexColor ::= "#" [0-9a-fA-F] [0-9a-fA-F] [0-9a-fA-F] [0-9a-fA-F] [0-9a-fA-F] [0-9a-fA-F]
digit ::= [0-9]
digits ::= digit+
intNumber ::= digits
floatNumber ::= (digits? ".")? digits
negativeFloat ::= ("-")? floatNumber
coordinate ::= negativeFloat ", " negativeFloat

2024-10-18 12:50:12,624:WARNING:Few-shot examples file sensors/few_shot_examples.json not found: [Errno 2] No such file or directory: 'sensors/few_shot_examples.json'. Continuing without few-shot examples.
2024-10-18 12:50:12,626:ERROR:Unexpected error in __main__.deploy_selected_model: cannot access local variable 'message' where it is not associated with a value
2024-10-18 12:50:12,631:ERROR:Traceback: Traceback (most recent call last):
  File "/Users/lucasala/Documents/Projects/Maktaba/text-to-DSL/main.py", line 41, in deploy_selected_model
    if test_model(dataset_name, selected_model_name, system_prompt_version):
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/lucasala/Documents/Projects/Maktaba/text-to-DSL/scripts/model_testing.py", line 204, in test_model
    message = build_message(model_name, system_prompt, grammar, few_shot_examples, example)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/lucasala/Documents/Projects/Maktaba/text-to-DSL/scripts/message_builder.py", line 20, in build_message
    message += f"Rules that need to be followed to write the code:\n{grammar}\n\n"
    ^^^^^^^
UnboundLocalError: cannot access local variable 'message' where it is not associated with a value

2024-10-18 12:50:12,631:INFO:Process completed successfully.
2024-10-18 12:51:16,465:INFO:Starting the pipeline with the following steps: ['data_validation', 'configure_prompt_version', 'test_model', 'analyze_results', 'manage_experiment_logs', 'generate_visualizations']
2024-10-18 12:51:16,465:INFO:Starting data validation...
2024-10-18 12:51:17,237:INFO:Simple examples loaded successfully.
2024-10-18 12:51:17,238:INFO:Complex examples loaded successfully.
2024-10-18 12:51:17,276:INFO:Data validation completed successfully. All entries conform to the schema.
2024-10-18 12:51:17,276:INFO:Updating prompt versions...
2024-10-18 12:51:17,558:INFO:Deploying models...
2024-10-18 12:51:17,560:INFO:Available supported models: ['Qwen 2.5-coder (7B) quantized 4bit', 'Qwen 2.5-coder (7B) full precision', 'Qwen 2.5 (32B) full precision', 'Qwen 2.5 (72B) quantized 4bit', 'Qwen 2.5 (72B) quantized 8bit', 'Codellama (7B) full precision', 'Codellama (13B) full precision', 'Codellama (34B) full precision', 'Codellama (70B) full precision', 'LLaMA 3.1 (8B) full precision', 'LLaMA 3.1 (70B) quantized 4bit', 'LLaMA 3.1 (70B) quantized 8bit', 'StarCoder2 (3B) full precision', 'StarCoder2 (7B) full precision', 'StarCoder2 (15B) full precision', 'Mistral (7B) full precision', 'OpenAI GPT4o']
2024-10-18 12:51:18,236:INFO:Selected model: Qwen 2.5-coder (7B) quantized 4bit
2024-10-18 12:51:18,901:INFO:Parameters for model Qwen 2.5-coder (7B) quantized 4bit configured successfully.
2024-10-18 12:51:18,902:WARNING:Synthetic data file not found: [Errno 2] No such file or directory: 'data/sensors/augmented_examples.json'. Continuing without synthetic data.
2024-10-18 12:51:18,902:WARNING:No specific configuration found for model Qwen 2.5-coder quantized 4bit. Using default settings.
2024-10-18 12:51:18,903:INFO:Testing model Qwen 2.5-coder quantized 4bit with 4 examples and parameters: {}.
2024-10-18 12:51:18,903:WARNING:System prompt version {'version': '1.0', 'prompt': 'You are a helpful assistant.', 'rationale': 'Basic system prompt', 'timestamp': '2024-10-10T10:00:00'} not found. Defaulting to version 1.0.
2024-10-18 12:51:18,903:INFO:Using system prompt: You are a helpful assistant.
2024-10-18 12:51:18,903:INFO:Grammar for sensors loaded successfully.
2024-10-18 12:51:18,904:INFO:Using grammar: I need you to use this grammar for a set of instructions that I will be giving you:

root ::= parse
parse ::= sentence+
sentence ::= createStatement
createStatement ::= "CREATE " (createProduct | createRange | createDimension | createSensor)
createProduct ::= "PRODUCT " identifier " USING " srid ";\n\n"
createRange ::= "RANGE " identifier " (\n" rangeProperty (",\n" rangeProperty)* "\n)" ";\n\n"
rangeProperty ::= rangeNumber (" TO " rangeNumber)? " AS " text (" COLOR " hexColor)? | " DEFAULT " "AS " text (" COLOR " hexColor)?
rangeNumber ::= identifier | floatNumber | intNumber | "INFINITY" | "-INFINITY"
createDimension ::= createSpatialDimension | createCategoricalDimension
createSpatialDimension ::= "SPATIAL DIMENSION " identifier " (\n" "\tgeometry" ":" (type | " Geometry") "\n)" createDimensionProperties createParentDimension? ";\n\n"
createCategoricalDimension ::= "CATEGORICAL DIMENSION " identifier " (\n" "FIELD" ":" identifier ")" ";\n\n"
createParentDimension ::= " WITH PARENT " "(\n" identifier (",\n" identifier)* "\n)"
createDimensionProperties ::= " WITH PROPERTIES " "(\n" dimPropertyDefinition (",\n" dimPropertyDefinition)* "\n)"
dimPropertyDefinition ::= "\t" identifier type
createSensor ::= "SENSOR " identifier " (\n" "\tinterval" ": " intNumber ",\n" "\tdatasource" ": " dataSource ",\n" "\tgeometry" ":" type "\n)" createSensorProperties createSensorMeasurementData (addSpatialDimensionToSensor)* (addCategoricalDimensionToSensor)? (addBBXToSensor)? ";\n\n"
createSensorProperties ::= " WITH PROPERTIES " "(\n" sensorPropertyDefinition (",\n" sensorPropertyDefinition)* "\n)"
sensorPropertyDefinition ::= "\t" identifier type
createSensorMeasurementData ::= " WITH MEASUREMENT DATA " "(\n" createMeasurementProperty (",\n" createMeasurementProperty)* "\n)"
createMeasurementProperty ::= "\t" identifier type (" UNITS " text)? (" ICON " text)? (" RANGE " identifier)?
addSpatialDimensionToSensor ::= " WITH SPATIAL DIMENSIONS " identifier "(\n" "\t" identifier (",\n" "\t" identifier)* "\n)"
addCategoricalDimensionToSensor ::= " WITH CATEGORICAL DIMENSIONS " "(\n" "\t" identifier (" RANGE " identifier)? (",\n" "\t" identifier (" RANGE " identifier)?)* "\n)"
addBBXToSensor ::= " WITH BBOX " "(" ("[")? coordinate ("]")? ", " intNumber")"
srid ::= intNumber
identifier ::= text
text ::= [a-zA-Z] [a-zA-Z]? [a-zA-Z]? [a-zA-Z]? [a-zA-Z]? [a-zA-Z]? [a-zA-Z]? [a-zA-Z]? [a-zA-Z]? [a-zA-Z]?
quotedText ::= "\"" text "\""
ws ::= ([ \t\n] ws)?
type ::= " Long" | " Boolean" | " Float" | " Integer" | " Double" | " Localdate" | " String" | " Datetime" | " Linestring" | " Multilinestring" | " Polygon" | " Multipolygon" | " Point" | " Multipoint"
dataSource ::= "postgres" | "elasticsearch"
hexColor ::= "#" [0-9a-fA-F] [0-9a-fA-F] [0-9a-fA-F] [0-9a-fA-F] [0-9a-fA-F] [0-9a-fA-F]
digit ::= [0-9]
digits ::= digit+
intNumber ::= digits
floatNumber ::= (digits? ".")? digits
negativeFloat ::= ("-")? floatNumber
coordinate ::= negativeFloat ", " negativeFloat

2024-10-18 12:51:18,904:WARNING:Few-shot examples file sensors/few_shot_examples.json not found: [Errno 2] No such file or directory: 'sensors/few_shot_examples.json'. Continuing without few-shot examples.
2024-10-18 12:51:18,904:ERROR:Unexpected error in __main__.deploy_selected_model: name 'prompt' is not defined
2024-10-18 12:51:18,909:ERROR:Traceback: Traceback (most recent call last):
  File "/Users/lucasala/Documents/Projects/Maktaba/text-to-DSL/scripts/model_testing.py", line 210, in test_model
    response = client.chat.completions.create(
               ^^^^^^
NameError: name 'client' is not defined

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/lucasala/Documents/Projects/Maktaba/text-to-DSL/main.py", line 41, in deploy_selected_model
    if test_model(dataset_name, selected_model_name, system_prompt_version):
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/lucasala/Documents/Projects/Maktaba/text-to-DSL/scripts/model_testing.py", line 221, in test_model
    logging.warning(f"Attempt {attempt + 1} failed for model {model_name} on input '{prompt}': {e}")
                                                                                     ^^^^^^
NameError: name 'prompt' is not defined

2024-10-18 12:51:18,909:INFO:Process completed successfully.
